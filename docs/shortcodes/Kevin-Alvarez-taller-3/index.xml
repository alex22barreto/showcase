<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Showcase Template</title><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/</link><description>Recent content on Showcase Template</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/index.xml" rel="self" type="application/rss+xml"/><item><title/><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Image-Processing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Image-Processing/</guid><description>Image Processing # Background # We can use a different set of algorithms to process (modify, transform) and image, in this case, we are going to use Convolutional Masks to transform an image and obtain different features of the image, and also we can see different effects on the image.
Convolutional Masks # Is a small matrix (in our case is a 9x9 matrix) which includes weightings (set of values that gives &amp;ldquo;relevance&amp;rdquo;) which are applied on pixel values in order to change the image and create different effects.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Normal-Map-Test/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Normal-Map-Test/</guid><description>Testing Lighting and Normal Mapping # Background # Result # Extremely slow, start at your own risk.
Move your mouse to see how light interacts with the image.
Taken from Andor Saga at : https://openprocessing.org/sketch/1221468</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Procedural-Texturing/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Procedural-Texturing/</guid><description>Procedural Texturing # Background # Is the method of generating textures by providing a set of parameters, these parameters are sent to an algorithm (in our case a shader) and it will create its own variations, using this method, computers generate data automatically, it is quite useful to make large textures , that wouldn&amp;rsquo;t be practical doing by hand, also reduces the need of storage for textures, and provides almost unlimited texture resolution.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Texture-Sampling/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Texture-Sampling/</guid><description>Texture Sampling # Background # The main idea is to treat our image like a set of values, this allows us to sample it, or getting a finite number of values from said image, we then, can play with these values adding more effects, or altering the properties of our image, or even applying filters.
Luma # Luma allows us to see the light intensity in an image, by removing color, it shows areas with greater luminance in a whiter color, and a darker color in areas without light.</description></item><item><title/><link>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Texturing-and-Coloring/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://visualcomputing.github.io/showcase/docs/shortcodes/Kevin-Alvarez-taller-3/Texturing-and-Coloring/</guid><description>Texturing and Coloring # Background # We can use shaders as a texture, this allows us to give any 3d object a more dynamic appearance, shaders are simple scripts that allows us to map a color to each pixel of a given image, using parameters such as model coordinates. In this workshop we faced the challenge of mapping a shader on a non-primitive object, that is, using begin and end shape on p5, we faced some issues, the main one was that the shader was never applied on our shape, to solve this issue we needed to send the texture coordinates to a vertex shader, which is later sent to the fragment shader, this method allowed us to map our shader as a texture.</description></item></channel></rss>